#include "genEngine.hpp"

namespace build_engine{

bool genEngine(std::string onnx_file_path, std::string save_engine_path, trtlogger::Logger level, int maxbatch){

    auto logger = std::make_shared<trtlogger::Logger>(level);

    // åˆ›å»ºbuilder
    auto builder = std::unique_ptr<nvinfer1::IBuilder>(nvinfer1::createInferBuilder(*logger));
    if(!builder){
        std::cout<<" (T_T)~~~, Failed to create builder."<<std::endl;
        return false;
    }

    auto network = std::unique_ptr<nvinfer1::INetworkDefinition>(builder->createNetworkV2(0U));

    if(!network){
        std::cout<<" (T_T)~~~, Failed to create network."<<std::endl;
        return false;
    }

    // åˆ›å»º config
    auto config = std::unique_ptr<nvinfer1::IBuilderConfig>(builder->createBuilderConfig());
    if(!config){
        std::cout<<" (T_T)~~~, Failed to create config."<<std::endl;
        return false;
    }

    // åˆ›å»ºparser ä»Žonnxè‡ªåŠ¨æž„å»ºæ¨¡åž‹ï¼Œå¦åˆ™éœ€è¦è‡ªå·±æž„å»ºæ¯ä¸ªç®—å­
    auto parser = std::unique_ptr<nvonnxparser::IParser>(nvonnxparser::createParser(*network, *logger));
    if(!parser){
        std::cout<<" (T_T)~~~, Failed to create parser."<<std::endl;
        return false;
    }

    // è¯»å–onnxæ¨¡åž‹æ–‡ä»¶å¼€å§‹æž„å»ºæ¨¡åž‹
    auto parsed = parser->parseFromFile(onnx_file_path.c_str(), 1);
    if(!parsed){
        std::cout<<" (T_T)~~~ ,Failed to parse onnx file."<<std::endl;
        return false;
    }


    {
        auto input = network->getInput(0);
        auto input_dims = input->getDimensions();
        auto profile = builder->createOptimizationProfile(); 

        // é…ç½®æœ€å°ã€æœ€ä¼˜ã€æœ€å¤§èŒƒå›´
        input_dims.d[0] = 1;                                                         
        profile->setDimensions(input->getName(), nvinfer1::OptProfileSelector::kMIN, input_dims);
        profile->setDimensions(input->getName(), nvinfer1::OptProfileSelector::kOPT, input_dims);
        input_dims.d[0] = maxbatch;
        profile->setDimensions(input->getName(), nvinfer1::OptProfileSelector::kMAX, input_dims);
        config->addOptimizationProfile(profile);

        // åˆ¤æ–­æ˜¯å¦ä½¿ç”¨åŠç²¾åº¦ä¼˜åŒ–æ¨¡åž‹
        // if(FP16)  
        config->setFlag(nvinfer1::BuilderFlag::kFP16);

        config->setFlag(nvinfer1::BuilderFlag::kGPU_FALLBACK);
        config->setDefaultDeviceType(nvinfer1::DeviceType::kDLA);

        // è®¾ç½®é»˜è®¤è®¾å¤‡ç±»åž‹ä¸º DLA
        config->setDefaultDeviceType(nvinfer1::DeviceType::kDLA);

        // èŽ·å– DLA æ ¸å¿ƒæ”¯æŒæƒ…å†µ
        int numDLACores = builder->getNbDLACores();
        if (numDLACores > 0) {
            std::cout << "DLA is available. Number of DLA cores: " << numDLACores << std::endl;

            // è®¾ç½® DLA æ ¸å¿ƒ
            int coreToUse = 0; // é€‰æ‹©ç¬¬ä¸€ä¸ª DLA æ ¸å¿ƒï¼ˆå¯ä»¥æ ¹æ®å®žé™…éœ€æ±‚ä¿®æ”¹ï¼‰
            config->setDLACore(coreToUse);
            std::cout << "Using DLA core: " << coreToUse << std::endl;
        } else {
            std::cerr << "DLA not available on this platform, falling back to GPU." << std::endl;
            
            // å¦‚æžœ DLA ä¸å¯ç”¨ï¼Œåˆ™è®¾ç½® GPU å›žé€€
            config->setFlag(nvinfer1::BuilderFlag::kGPU_FALLBACK);
            config->setDefaultDeviceType(nvinfer1::DeviceType::kGPU);
        }
    };

    config->setMemoryPoolLimit(nvinfer1::MemoryPoolType::kWORKSPACE, 1 << 28);      /*åœ¨æ–°çš„ç‰ˆæœ¬ä¸­è¢«ä½¿ç”¨*/

    // åˆ›å»ºåºåˆ—åŒ–å¼•æ“Žæ–‡ä»¶
    auto plan = std::unique_ptr<nvinfer1::IHostMemory>(builder->buildSerializedNetwork(*network, *config));
    if(!plan){
        std::cout<<" (T_T)~~~, Failed to SerializedNetwork."<<std::endl;
        return false;
    }

    //! æ£€æŸ¥è¾“å…¥éƒ¨åˆ†æ˜¯å¦ç¬¦åˆè¦æ±‚
    auto numInput = network->getNbInputs();
    std::cout<<"æ¨¡åž‹çš„è¾“å…¥ä¸ªæ•°æ˜¯ï¼š"<<numInput<<std::endl;
    for(auto i = 0; i<numInput; ++i){
        std::cout<<"    æ¨¡åž‹çš„ç¬¬"<<i<<"ä¸ªè¾“å…¥ï¼š";
        auto mInputDims = network->getInput(i)->getDimensions();
        std::cout<<"  âœ¨~ model input dims: "<<mInputDims.nbDims <<std::endl;
        for(size_t ii=0; ii<mInputDims.nbDims; ++ii){
            std::cout<<"  âœ¨^_^ model input dim"<<ii<<": "<<mInputDims.d[ii] <<std::endl;
        }
    }

    auto numOutput = network->getNbOutputs();
    std::cout<<"æ¨¡åž‹çš„è¾“å‡ºä¸ªæ•°æ˜¯ï¼š"<<numOutput<<std::endl;
    for(auto i=0; i<numOutput; ++i){
        std::cout<<"    æ¨¡åž‹çš„ç¬¬"<<i<<"ä¸ªè¾“å‡ºï¼š";
        auto mOutputDims = network->getOutput(i)->getDimensions();
            std::cout<<"  âœ¨~ model output dims: "<<mOutputDims.nbDims <<std::endl;
            for(size_t jj=0; jj<mOutputDims.nbDims; ++jj){
                std::cout<<"  âœ¨^_^ model output dim"<<jj<<": "<<mOutputDims.d[jj] <<std::endl;
            }
    }

    // åºåˆ—åŒ–ä¿å­˜æŽ¨ç†å¼•æ“Žæ–‡ä»¶æ–‡ä»¶
    std::ofstream engine_file(save_engine_path, std::ios::binary);
    if(!engine_file.good()){
        std::cout<<" (T_T)~~~, Failed to open engine file"<<std::endl;
        return false;
    }

    engine_file.write((char *)plan->data(), plan->size());
    engine_file.close();

    std::cout << " ~~Congratulations! ðŸŽ‰ðŸŽ‰ðŸŽ‰~  Engine build success!!! âœ¨âœ¨âœ¨~~ " << std::endl;

    return true;

}

} // build_engine